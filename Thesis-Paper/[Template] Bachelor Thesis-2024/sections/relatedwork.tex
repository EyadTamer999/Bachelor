\chapter{Related Work}\label{chap:related}

Image splicing detection has evolved through various methodologies, including traditional techniques, deep learning approaches, and splicing localization methods \cite{Khazaal2022}. This chapter explores the wide range of relevant works and charts the developments made in the field of image splicing research. Firstly, the discussion unfolds around early traditional techniques comprising handcrafted feature-based methods. Then we explore contemporary methods levering deep learning architectures. Finally, we highlight the efforts dedicated to the task of localizing the spliced regions.


  \section{Handcrafted feature-based methods} \label{sec:s1}
  
In this section, we explore traditional image splicing detection methods, also referred to as handcrafted feature-based methods. These methods involve the manual creation and extraction of specific features from images, such as texture patterns, color variations, and statistical properties, and relying on inconsistencies within them to identify manipulations \cite{Ma_Jiang_Fan_Jiang_Yan_2020}. We explore the most commonly \cite{MeenaTyagi2021} used methods which are: 
\begin{enumerate}
  \item \hyperref[sec:ss1]{Noise-based Methods}
  \item \hyperref[sec:ss2]{Textural feature-based Methods}
  \item \hyperref[sec:ss3]{Markov feature-based Methods}
\end{enumerate}

\subsection{Noise-based Methods} \label{sec:ss1}

Noise-based methods identify manipulations by analyzing inconsistencies in noise patterns. Digital images acquire noise during capture, stemming from light (physical noise) and sensor imperfections (hardware noise). Images captured on different cameras will have inherently different noise levels, resulting in spliced photos displaying uneven noise patterns \cite{verma2013comparative}. Various methods have been devised to identify image splicing forgeries by utilizing noise variations. Meena and Tyagi \cite{meena2023image} introduced a noise level estimation method that utilizes irregular-shaped superpixel blocks, employing the Simple Linear Iterative Clustering (SLIC) technique. The approach relies on principal component analysis (PCA) for image estimation and k-means clustering to differentiate between authentic and spliced blocks based on noise levels. Another approach by Itier et. al \cite{itier2021color} focuses on color noise correlation analysis across RGB channels, exploiting intrinsic features of image acquisition to detect spliced areas by identifying blocks spanning both the background and spliced regions. Additionally, a PCA noise estimation method, proposed by Zhan et. al \cite{zhan2015passive}, capitalizes on variations in noise levels across images from different sources, identifying inconsistencies in local noise levels. The study \cite{mahawatta2018image} suggested a noise pattern analysis method, segmenting images into non-overlapping blocks and estimating noise variances through wavelet transformations on the luminance component of the image.

\subsubsection{Error Level Analysis}\label{sec:ss2}

A tool called error level analysis (ELA), which can evaluate images with different levels of compression, was proposed in a study \cite{krawetz2007picture}. In ELA, an image is first compressed at a known error rate, and then the difference between the original and compressed versions is analyzed. Regions that exhibit higher error levels than the surrounding areas are considered potential areas of interest for further investigation. ELA is based on the premise that authentic images typically have consistent error levels across the entire image, while manipulated regions may show variations in error levels. ELA specifically ties into the detection of forgeries in JPEG images. JPEG compression introduces quantization errors, and these errors are more pronounced in regions of the image that have been modified or manipulated. ELA takes advantage of these errors to highlight potential areas of interest for further investigation \cite{gunawan2017development}. \cite{Jeronymo2017} examines and demonstrates the great reliability of this technique for detecting image splicing. A method for forgery detection in lossy compressed digital images employing ELA and filtering its noise components using automatic wavelet soft thresholds was proposed in 2019 \cite{ramadhani2019}. More recently, a study combined ELA with the Local Binary Pattern (LBP) for splicing detection, achieving an accuracy score of 91.46\% on the Columbia dataset, a benchmark dataset consisting of 363 images \cite{zhang2021image}.


\subsection{Textural Feature-Based Methods}\label{sec:ss2}

Textural Feature-Based Methods focus on texture analysis to detect splicing. Texture analysis attempts to quantify texture qualities described by terms such as rough, smooth, silky, or bumpy as a function of the spatial variation in pixel intensities \cite{haralick1973textural}. In image splicing forgery, new micro-patterns replace the original ones in the spliced area, making edges sharp along the spliced region boundaries. Consequently, the local frequency distributions in the spliced image notably differ from those in an authentic image. Additionally, each source image contributing to a composite image may have a distinct spatial arrangement of colors or intensities \cite{asghar2019edge}. Alahmadi et al. \cite{alahmadi2017passive} proposed a method using LBP and DCT, emphasizing its efficiency in detecting both copy-move and splicing forgeries. Sharma and Ghanekar \cite{Sharma2019} proposed an algorithm based on Local Directional Pattern (LDP), unique for its combined ability to classify spliced images and localize the specific tampered regions. Srivastava and Yadav \cite{Srivastava2020} presented an approach utilizing Enhanced Local Ternary Pattern (ELTP) for feature extraction, surpassing the performance of Local Binary Pattern (LBP). Following this, Kanwal et al. \cite{kanwal2020digital} introduced a novel block-based approach leveraging the Otsu-based Enhanced Local Ternary Pattern (OELTP) for feature extraction, enhancing the forgery detection capabilities of the existing Enhanced Local Ternary Pattern (ELTP).

\subsection{Markov Feature-Based Methods} \label{sec:ss3}

Markov Feature-Based methods analyze pixel dependencies, considering not only individual pixel characteristics but also their interactions with neighboring pixels, enabling the detection of subtle patterns and inconsistencies that may not be apparent when analyzing isolated features \cite{pham2019efficient}. Because of their ability to capture these nuances, they have been widely studied \cite{MeenaTyagi2021} and achieved overwhelming success. Rhhman et al. \cite{ur2021comparative} conducted a comparative analysis of image splicing algorithms, introducing an enhanced technique that combines Discrete Cosine Transform Domain (DTC) with Markov features in the spatial domain. The authors utilize Principal Component Analysis (PCA) to select significant features and apply Support Vector Machine (SVM) for classification on a publicly available dataset using ten-fold cross-validation. Yildirim \cite{yildirim2018image} presents a method for image splicing detection with Discrete Wavelet Transform (DWT) domain extended Markov features, utilizing a combination of DWT and Markov-based methods for feature extraction, followed by Support Vector Machine classification. Furthermore, Pham et al. \cite{pham2019efficient} introduced an efficient image splicing detection algorithm based on Markov features. Their method involves applying Discrete Wavelet Transform to the image and extracting four-direction Markov features for subsequent classification using Support Vector Machines. Yildirim \& Ulutaş \cite{yildirim2018markov} proposed a Markov-based method in the Discrete Cosine Transform domain to detect image splicing forgery. They extract Markov features from high-frequency coefficients obtained through DCT and employ Support Vector Machines for image classification. Notably, they achieved the highest accuracy rate of 99.98\%, underscoring the efficacy of Markov-based forgery detection methods across diverse domains and methodologies. However, Markov models suffer from the complexity of calculations and time consumption.

Through this discussion, the importance of traditional and handcrafted feature-based methods and their contributions and limitations become clear, setting the stage for an exploration of more contemporary and automated approaches in the following section.

  \section{Deep Learning Methods } \label{sec:s2}

Traditionally, image characteristics were extracted by employing various filters or descriptors. However, as the diversity of features within an image grows, the task of designing filters to extract each type of feature becomes increasingly complex \cite{MeenaTyagi2021}. Moreover, relying on expert opinions to select suitable filters for highlighting specific aspects adds an additional layer of challenge. The emergence of deep learning has effectively addressed these limitations, offering the capability for automatic learning of intricate feature representations \cite{Wicht2018}. In this section, we focus on the current state-of-the-art technology for forgery detection: CNNs.

In recent years, the landscape of image splicing forgery detection has witnessed a surge in methods leveraging deep learning techniques. Prominent among these frameworks are Deep Boltzmann Machines \cite{salakhutdinov2009}, Deep Autoencoders \cite{larochelle2009exploring}, and Convolutional Neural Networks (CNNs) \cite{ciresan2011flexible, krizhevsky2012imagenet, ji2012}. Demonstrating impressive performance across various artificial intelligence tasks, these deep learning architectures have served as foundational elements for more advanced models.

Prior to the widespread adoption of CNNs, early endeavors in splicing detection and localization predominantly employed autoencoders. Functioning as neural networks that utilize fewer bits to reconstruct an input image, autoencoders have played a crucial role in identifying and localizing tampered regions on a patch-wise basis. These networks utilize wavelet features as input and can incorporate additional local noise features, such as the Spatial Rich Model (SRM), widely used in steganalysis—the study and detection of hidden messages in digital media \cite{fridrich2012rich}. SRM employs manually crafted filters to extract nearby pixel-level noise, facilitating the differentiation between manipulated and original regions. Notably, SRM filters have found application in creating specialized inputs for CNNs. In \cite{Cozzolino2016}, authors used SRM features as input for their autoencoder model. Futhermore, in \cite{rao2016}, Rao and Ni proposed to use 30 SRM filters as initialization for the first layer in a CNN to detect splicing and copy-move forgeries. The results from the pre-trained CNN were used in an SVM classifier for determining whether the images were forged.

  \subsection{Convolutional Neural Networks } \label{sec:ss3}

CNN, particularly effective in discovering spatial correlations, is able to combine image segmentation, feature extraction, and classification, to provide an automatic and general approach for authenticating or detecting forged images \cite{tyagi2023mininet}, \cite{bunk2017detection}, \cite{wang2019detection},  \cite{zanardelli2023image}. This intelligent application of deep learning helps model and identify structural changes indicative of forgery, offering a robust solution to the challenges in forgery detection.


Rao et al. \cite{Rao2020DeepLL} introduced a deep learning-based method for image splicing detection, employing a convolutional neural network (CNN) to automatically learn hierarchical features from input images. The approach incorporates high-pass filters to extract noise residuals and utilizes an SVM classifier for further classification. In a similar vein, Liu et al. \cite{liu2018locating} devised a deep learning model for image splicing forgery detection, incorporating a conditional random field (CRF) to adaptively integrate results from CNNs. CRFs are probabilistic graphical models used to model relationships between pixels in an image, particularly useful for refining and post-processing. The authors reported superior performance compared to existing methods. Pomari et al. \cite{pomari2018image} proposed a method combining illumination inconsistencies and deep learning to reveal image splicing. Subsequently, Chen et al. \cite{chen2018improved} enhanced the methodology introduced by Liu et al. \cite{liu2018locating}, introducing a novel approach using three fully convolutional networks (FCNs) with distinct upsampling layers. Furthermore, the authors initialized these FCNs with pretrained weights from the VGG-16 network, contributing to improved performance in image splicing detection. FCNs differ from traditional CNNs by replacing fully connected layers with convolutional layers, enabling pixel-wise predictions and making them well-suited for tasks like image segmentation.

Ahmed et al. \cite{ahmed2020image} introduced a new backbone architecture for deep learning called ResNet-conv. ResNet-conv is obtained by replacing the feature pyramid network (FPN) in Residual Network (ResNet)-FPN with a set of convolutional layers. This new backbone is used to generate the initial feature map, which is then used to train the Mask-Region-based Convolutional Neural Network (RCNN) to generate masks for spliced regions in forged images. Recently, Guo et al. \cite{guo2023hierarchical} developed a novel hierarchical fine-grained formulation for Image Forgery Detection and Localization (IFDL), utilizing multiple labels at different levels to capture hierarchical dependencies and improve performance across seven benchmarks. Tyagi and Yadav \cite{tyagi2023mininet} presented a compact Convolutional Neural Network (CNN) tailored for image forgery detection, showcasing efficiency in feature extraction and authenticity classification on both the CASIA V2 and COVERAGE datasets.


  \section{Localization of Image Splicing } \label{sec:s3}
  As previously stated, the second step to an image forgery detection method is the localization step, whereby the region of tampering is highlighted, traditionally in the form of a black and white mask. Since forgery localization goes hand in hand with forgery detection, it has also gone through the familiar evolution from traditional handcrafted features to deep learning methods, with ViTs being a rapidly emerging technology in forgery localization. The contributions that led to this development will be explored in this section.

Several traditional approaches \cite{bianchi2011improved}, \cite{luo2010jpeg}, \cite{lin2009fast} have utilized JPEG blocking artifacts to detect tampered regions. As previously mentioned, JPEG, as previously mentioned, is a lossy compression that divides an image into blocks and applies DCT to each block, followed by quantization. The process introduces specific blocking artifacts, which can be exploited for tampering detection and localization, utilizing quantitative measures, such as the Mean Squared Error (MSE) or Structural Similarity Index (SSI), to assess the blockiness introduced by splicing. Sharma and Ghanekar \cite{Sharma2019} tackled the task of localization through splitting the chrominance component of the query image into overlapping blocks and calculating the Local Directional Pattern (LDP) of each block. The standard deviation of each block is then used as a clue to visualize the spliced region.

The introduction of deep learning approaches into the forgery detection field meant that traditional approaches could be enhanced using new technologies; \cite{wang2019detection} developed an improved Mask R-CNN which attaches a Sobel filter to the mask branch of the Mask R-CNN. The authors use Mask-RCNN to localize the forgery for its unique ability to identify and segment objects at the pixel level. The Sobel filter acts as an auxiliary task to encourage predicted masks to have similar image gradients to the ground-truth mask. Similarly, Rao et al. \cite{Rao2020DeepLL} designed and implemented a CNN with the first layer of the network initialized with 30 SRM filters to locate splicing forgeries that were meant to improve on their previous work \cite{rao2016}. Based on the pre-trained CNN model, an image splicing localization scheme was developed by incorporating the fully connected Conditional Random Field (CRF), which has shown superior performance in semantic segmentation under the framework of deep learning \cite{noh2015learning}. In \cite{huh2018fighting}, a Siamese CNN with a self-consistency approach to determine if contents had been produced by a single device was proposed. The proposed model could predict the probability that two patches had similar Exchangeable Image File (EXIF) attributes and output a heatmap, highlighting image regions that had undergone possible forgery. Bunk et al. \cite{bunk2017detection} proposed a hybrid CNN-Long Short Term Memory (LSTM) model that captures the boundary discrepancy, or spatial structure, between manipulated and non-manipulated regions. The model was trained end-to-end using ground-truth mask information.

  \subsection{Vision Transformers } \label{sec:ss4}

 One of the earliest works in this realm, to the best of our knowledge, was a 2021 paper that proposed a technique that utilizes a ViT to localize manipulated areas within satellite images \cite{horváth2021manipulation}. The method relies heavily on a basic ViT architecture and requires no labeled data, making it cost effective and a scalable solution. To reduce the memory used by the self-attention module in the transformer, they used the Linformer \cite{wang2020linformer} to reduce the space complexity from the original ViT from quadratic complexity to linear. The authors also created their own dataset of satellite images to mitigate the issue of training data quality. 
 
 A more general-purpose method called TransForensics \cite{hao2021transforensics} was developed to localize manipulations in regular images. The architecture uses dense self-attention encoders and dense correction modules to model global context and interactions between local patches at different scales. TransForensics is able to capture discriminative representations and generate high-quality mask predictions for various types of tampering, regardless of the order of patch sequences. TransForensics proved to outperform state-of-the-art models, mostly CNNs, on datasets such as CASIA, COVER, and IMD2020. The results of the proposed method were compared with various state-of-the-art models on these datasets and reported an outperforming F1 score of 0.884. ObjectFormer was a proposed method for detecting and localizing image manipulations \cite{wang2022objectformer}. The authors address the challenge of detecting subtle manipulation traces that are no longer visible in the RGB domain by using CNNs to extract high-frequency features from images and combining them with RGB features as multimodal patch embeddings. The embeddings are then passed through a ViT for further encoding. The model was evaluated on the CASIA, Columbia, Coverage, NIST16, and IMD2020 datasets, outperforming state-of-the-art approaches with an F1-score of 0.973.

The IML-ViT model introduced in 2023 presents a novel approach addressing the challenging task of Image Manipulation Localization (IML) \cite{ma2023imlvit}. By leveraging the self-attention mechanism in ViTs, the authors propose IML-ViT as a high-resolution, multi-scale model capable of capturing artifacts and detecting image manipulations. The paper highlights the limitations of existing CNN-based methods in handling non-semantic modeling and long-range dependencies, making a compelling case for the suitability of ViTs in IML. The authors pointed out the shortcomings of the existing ViT approaches, namely ObjectFormer \cite{wang2022objectformer} and TransForensics \cite{hao2021transforensics}; both approaches miss important first-hand low-level information since they use multiple CNN layers to first extract feature maps and then use transformers for additional encoding. Therefore, they aimed to simplify the architecture and introduced a morphology-based edge loss strategy to guide the model's focus on the boundaries of manipulated regions, further enhancing its localization performance. Through extensive experiments on benchmark datasets, such as CASIA V1 and Columbia, IML-ViT demonstrates superior performance compared to state-of-the-art methods in terms of accuracy and localization metrics, with the best F1-score being 0.658.


This thesis builds upon existing related work in the field, particularly \cite{ma2023imlvit} and \cite{zhang2021image}, aiming to address key gaps in current approaches to forgery detection. Specifically, it focuses on enhancing the generalization of deep models, revitalizing forensic techniques, and elevating data quality and availability. Firstly, recognizing the limitations of handcrafted feature-based methods, the thesis explores more automated and generalized techniques. Leveraging the power of the new and emerging ViTs, the research tailors these advancements to the unique challenges posed by online image manipulation. Secondly, the thesis proposes integrating ELA, an underexplored forensic technique, with DenseNet architecture to create the ELA-DenseNet model. This combination aims to improve the classification accuracy of forged images. Lastly, the research emphasizes the paramount importance of data quality and quantity. It introduces a an expanded dataset specifically curated and annotated for image splicing detection, strategically aligned with ViT's goal for enhanced performance in online forgery detection.


